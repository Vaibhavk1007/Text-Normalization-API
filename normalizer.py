# -*- coding: utf-8 -*-
"""Text-Normalizer.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zqUomykU1YTn687ytcfCe4wBaOvKUU5Q
"""

import re
import unicodedata
from dataclasses import dataclass
from typing import List

def sanitize_text(text: str) -> str:
    # Normalize unicode
    text = unicodedata.normalize("NFKC", text)

    # Normalize line endings
    text = text.replace("\r\n", "\n").replace("\r", "\n")

    # Smart quotes â†’ normal quotes
    quotes = {
        "â€œ": '"', "â€": '"',
        "â€˜": "'", "â€™": "'"
    }
    for k, v in quotes.items():
        text = text.replace(k, v)

    # Normalize non-breaking spaces
    text = text.replace("\u00A0", " ")

    return text

@dataclass
class Line:
    raw: str
    kind: str  # HEADER, BODY, LIST_ITEM, FOOTER, PAGE_NUMBER, SEPARATOR, NOISE

def classify_line(line: str) -> str:
    stripped = line.strip()

    if not stripped:
        return "NOISE"

    if re.fullmatch(r"Page\s+\d+\s+of\s+\d+", stripped, re.I):
        return "PAGE_NUMBER"

    if re.fullmatch(r"[â€”\-_=]{3,}", stripped):
        return "SEPARATOR"

    if stripped.isupper() and len(stripped) < 80:
        return "HEADER"

    if re.match(r"^(\d+[\.\)]|[a-zA-Z][\)])\s+", stripped):
        return "LIST_ITEM"

    if len(stripped) < 3:
        return "NOISE"

    return "BODY"

def remove_non_content(lines: List[Line]) -> List[Line]:
    return [
        l for l in lines
        if l.kind not in {"PAGE_NUMBER", "SEPARATOR", "FOOTER"}
    ]

def repair_hyphenation(lines: List[Line]) -> List[Line]:
    repaired = []
    i = 0

    while i < len(lines):
        line = lines[i].raw.rstrip()

        # Case 1: hyphen at end of line + next line exists
        if line.endswith("-") and i + 1 < len(lines):
            next_line = lines[i + 1].raw.lstrip()
            merged = line[:-1] + next_line

            # ðŸ”¥ PRESERVE ORIGINAL KIND
            repaired.append(Line(merged, lines[i].kind))
            i += 2
            continue

        # Case 2: inline OCR split like "be- tween"
        inline_fix = re.sub(r"(\w+)-\s+(\w+)", r"\1\2", line)

        # ðŸ”¥ PRESERVE ORIGINAL KIND
        repaired.append(Line(inline_fix, lines[i].kind))
        i += 1

    return repaired

def rebuild_paragraphs(lines: List[Line]) -> List[str]:
    paragraphs = []
    buffer = ""

    for l in lines:
        text = l.raw.strip()

        if l.kind == "HEADER" or text in {"AND"}:
            if buffer:
                paragraphs.append(buffer.strip())
                buffer = ""
            paragraphs.append(text)
            buffer = ""   # ðŸ”¥ THIS LINE FIXES HEADER GLUE
            continue

        if l.kind == "LIST_ITEM":
            if buffer:
                paragraphs.append(buffer.strip())
                buffer = ""
            paragraphs.append(text)
            continue

        if l.kind != "BODY":
            continue

        if buffer == "":
            buffer = text
        elif re.search(r"\b\d{5,6}$", buffer) or re.search(r"\b\d{5,6}$", text):
            paragraphs.append(buffer.strip())
            buffer = text
        elif buffer.endswith((".", ":", "!", "?")):
            paragraphs.append(buffer.strip())
            buffer = text
        elif buffer[-1].isdigit() and text[:1].isupper():
            paragraphs.append(buffer.strip())
            buffer = text

        elif buffer[-1].isdigit() and re.match(r"\d+\s*\)", text):
            paragraphs.append(buffer.strip())
            buffer = text
        else:
            buffer += " " + text

    if buffer:
        paragraphs.append(buffer.strip())

    return paragraphs

def normalize_spacing(text: str) -> str:
    # 1ï¸âƒ£ Collapse multiple spaces
    text = re.sub(r"[ \t]+", " ", text)

    # 2ï¸âƒ£ Remove space before punctuation
    text = re.sub(r"\s+([.,!?;:])", r"\1", text)

    # 3ï¸âƒ£ Normalize currency prefix
    text = re.sub(r"Rs\s*\.\s*", "Rs. ", text)

    # 4ï¸âƒ£ Fix currency suffix first (/-)
    text = re.sub(r"\s*/-\s*", "/-", text)

    # 5ï¸âƒ£ Fix OCR currency case: "45,000/ per" â†’ "45,000/- per"
    text = re.sub(r"(\d)/\s+per\b", r"\1/- per", text)

    # 6ï¸âƒ£ Normalize slashes in dates etc.
    text = re.sub(r"\s*/\s*", "/", text)

    # 7ï¸âƒ£ Ensure space after slash if followed by word
    text = re.sub(r"/(?=[A-Za-z])", "/ ", text)

    # 8ï¸âƒ£ Fix number comma spacing
    text = re.sub(r"(\d)\s*,\s*(\d)", r"\1,\2", text)

    # 9ï¸âƒ£ Fix ordinals: "5 th" â†’ "5th", "1 st" â†’ "1st"
    text = re.sub(r"\b(\d+)\s+(st|nd|rd|th)\b", r"\1\2", text, flags=re.I)

    # ðŸ”Ÿ Fix "No. 12 A" â†’ "No. 12A"
    text = re.sub(r"No\.\s*(\d+)\s+([A-Z])\b", r"No. \1\2", text)

    # 1ï¸âƒ£1ï¸âƒ£ Fix flat numbers: "12 A" â†’ "12A"
    text = re.sub(r"\b(\d+)\s+([A-Z])\b", r"\1\2", text)

    # 1ï¸âƒ£2ï¸âƒ£ Fix PIN codes: 411 045 â†’ 411045
    text = re.sub(r"\b(\d{3})\s+(\d{3})\b", r"\1\2", text)

    # 1ï¸âƒ£3ï¸âƒ£ Fix list markers: "2 )" â†’ "2)"
    text = re.sub(r"\b(\d+)\s+\)", r"\1)", text)

    return text.strip()

def remove_ocr_noise(text: str) -> str:
    # Remove stray OCR symbols
    text = re.sub(r"[|Â¬~]", "", text)

    # Remove excessive punctuation
    text = re.sub(r"([.!?]){3,}", r"\1", text)

    return text

def fix_inline_hyphens(text: str) -> str:
    # Merge word- word â†’ wordword (safe OCR fix)
    return re.sub(r"(?<=\w)-\s+(?=\w)", "", text)

def text_normalizer_pipeline(raw_text: str) -> str:
    original = raw_text  # snapshot for diff later

    text = sanitize_text(raw_text)
    lines = [Line(l, classify_line(l)) for l in text.split("\n")]
    lines = remove_non_content(lines)
    lines = repair_hyphenation(lines)

    paragraphs = rebuild_paragraphs(lines)

    cleaned = []
    for p in paragraphs:
        p = fix_inline_hyphens(p)   # âœ… ADD THIS
        p = normalize_spacing(p)
        p = remove_ocr_noise(p)
        cleaned.append(p)

    return "\n\n".join(cleaned)